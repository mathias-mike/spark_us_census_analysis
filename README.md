This project aims to analyze United States Census Bureau's 2017 Basic Monthly CPS using spark. A little note is that the data isn't actually that big and can be handled by a single machine without much cost (As was actually done), howeve the goal of the project is to demonstate knowledge in spark.

### Requirment
* Installation of jave and python. (Dependency for spark and pyspark)
* Local insatllation of spark. [Read the Doc](https://spark.apache.org/docs/latest/)
* Pyspark installation. Can be installed using pip

### Directory
* interswitch_task.ipynb is a notebook that shows the step by step process of extracting the data.
* etl.py is a python script that can be used to perform the same task as the notebook


[View powerpoint here!](https://docs.google.com/presentation/d/1LhCtQq-DNMEaBbd1Z8ET-rUDIlw6kc08/edit?usp=sharing&ouid=103429076205127856999&rtpof=true&sd=true)

Please pardon how rough this is as I don't have enough time to do a proper job with the task assigned on workdays and I had to squeez time from my work to attend to it. 